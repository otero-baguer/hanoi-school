{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural networks\n",
    "In this notebook we will start with the basics of neural networks for tasks such as regression and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of either TensorFlow or Theano, as well as other frameworks. It was developed with a focus on enabling fast experimentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (Regression)\n",
    "\n",
    "The first talk we are going to solve using neural networks is Regression. This is a supervised machine learning task, where the goal is to approximate an underlying function based on data observations. For this exercise the underlying function will be \n",
    "$$ f: \\mathbb{R} \\rightarrow \\mathbb{R}$$\n",
    "$$ f(x) = 10\\sin(\\pi x^2) + 20 (x-0.5)^ 2 + 15 *x$$\n",
    "\n",
    "**a)** Construct a dataset by first generating $500$ uniformly distributed $x_i$-samples and then computing $y_i = f(x_i) + 5\\eta_i$ where $\\eta_i \\sim \\mathcal{N}(0,1)$. Create a plot with the data-points and the underlying function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = np.sort(np.random.uniform(0, 3, 300))\n",
    "\n",
    "Y_true = 10 * np.sin(np.pi * X * X) + 20 * (X - 0.5) ** 2 + 15 * X \n",
    "\n",
    "Y = Y_true + np.random.normal(size=X.shape) * 2\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X, Y, color='red', s=5)\n",
    "plt.plot(X, Y_true, color='black', linestyle='--', linewidth=2.5)\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Split the data set into **training**, and **validation** sets and scale the values for achieving faster convergence. Plot the training points and the testing points with different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2c0af14a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = scale(X)\n",
    "Y = scale(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_train, Y_train, color='red', s=5, label='training')\n",
    "plt.scatter(X_test, Y_test, color='blue', s=5, label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Create a feed-forward neural network with one hidden layer. Train the network using the training set. Play around with the number of neurons and the number of layers to give more o less complexity to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "hidden1 = Dense(10, input_dim=1, activation='tanh')\n",
    "output = Dense(1, activation='linear')\n",
    "\n",
    "model.add(hidden1)   \n",
    "model.add(output)\n",
    "\n",
    "model.compile(optimizer=adam(0.01), loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3201 - val_loss: 0.1862\n",
      "Epoch 2/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1520 - val_loss: 0.1144\n",
      "Epoch 3/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1137 - val_loss: 0.1296\n",
      "Epoch 4/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.1271 - val_loss: 0.1280\n",
      "Epoch 5/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.1126 - val_loss: 0.1035\n",
      "Epoch 6/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0938 - val_loss: 0.0909\n",
      "Epoch 7/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0875 - val_loss: 0.0889\n",
      "Epoch 8/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0840 - val_loss: 0.0830\n",
      "Epoch 9/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0766 - val_loss: 0.0772\n",
      "Epoch 10/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0717 - val_loss: 0.0735\n",
      "Epoch 11/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0663 - val_loss: 0.0696\n",
      "Epoch 12/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0633 - val_loss: 0.0661\n",
      "Epoch 13/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0584 - val_loss: 0.0615\n",
      "Epoch 14/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0551 - val_loss: 0.0582\n",
      "Epoch 15/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0526 - val_loss: 0.0553\n",
      "Epoch 16/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0485 - val_loss: 0.0522\n",
      "Epoch 17/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0459 - val_loss: 0.0497\n",
      "Epoch 18/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0437 - val_loss: 0.0471\n",
      "Epoch 19/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0418 - val_loss: 0.0456\n",
      "Epoch 20/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0392 - val_loss: 0.0428\n",
      "Epoch 21/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0369 - val_loss: 0.0410\n",
      "Epoch 22/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0353 - val_loss: 0.0391\n",
      "Epoch 23/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0342 - val_loss: 0.0376\n",
      "Epoch 24/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0325 - val_loss: 0.0360\n",
      "Epoch 25/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0321 - val_loss: 0.0347\n",
      "Epoch 26/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0307 - val_loss: 0.0339\n",
      "Epoch 27/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0294 - val_loss: 0.0325\n",
      "Epoch 28/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0289 - val_loss: 0.0317\n",
      "Epoch 29/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0281 - val_loss: 0.0309\n",
      "Epoch 30/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0277 - val_loss: 0.0300\n",
      "Epoch 31/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0277 - val_loss: 0.0299\n",
      "Epoch 32/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0266 - val_loss: 0.0288\n",
      "Epoch 33/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0269 - val_loss: 0.0283\n",
      "Epoch 34/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0259 - val_loss: 0.0284\n",
      "Epoch 35/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0262 - val_loss: 0.0277\n",
      "Epoch 36/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0256 - val_loss: 0.0271\n",
      "Epoch 37/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0256 - val_loss: 0.0265\n",
      "Epoch 38/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0250 - val_loss: 0.0262\n",
      "Epoch 39/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0251 - val_loss: 0.0257\n",
      "Epoch 40/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0248 - val_loss: 0.0255\n",
      "Epoch 41/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0246 - val_loss: 0.0253\n",
      "Epoch 42/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0249 - val_loss: 0.0251\n",
      "Epoch 43/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0245 - val_loss: 0.0248\n",
      "Epoch 44/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0246 - val_loss: 0.0249\n",
      "Epoch 45/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0244 - val_loss: 0.0244\n",
      "Epoch 46/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0244 - val_loss: 0.0244\n",
      "Epoch 47/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 48/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0239 - val_loss: 0.0238\n",
      "Epoch 49/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0241 - val_loss: 0.0237\n",
      "Epoch 50/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0243 - val_loss: 0.0238\n",
      "Epoch 51/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0241 - val_loss: 0.0234\n",
      "Epoch 52/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0239 - val_loss: 0.0233\n",
      "Epoch 53/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0241 - val_loss: 0.0233\n",
      "Epoch 54/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0232\n",
      "Epoch 55/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0230\n",
      "Epoch 56/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0237 - val_loss: 0.0228\n",
      "Epoch 57/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0234 - val_loss: 0.0227\n",
      "Epoch 58/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0246 - val_loss: 0.0226\n",
      "Epoch 59/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0256 - val_loss: 0.0237\n",
      "Epoch 60/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0233\n",
      "Epoch 61/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0242 - val_loss: 0.0225\n",
      "Epoch 62/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0236 - val_loss: 0.0227\n",
      "Epoch 63/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0242 - val_loss: 0.0225\n",
      "Epoch 64/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0237 - val_loss: 0.0224\n",
      "Epoch 65/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0253 - val_loss: 0.0223\n",
      "Epoch 66/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0249 - val_loss: 0.0225\n",
      "Epoch 67/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0241 - val_loss: 0.0225\n",
      "Epoch 68/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0237 - val_loss: 0.0220\n",
      "Epoch 69/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0239 - val_loss: 0.0220\n",
      "Epoch 70/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0235 - val_loss: 0.0220\n",
      "Epoch 71/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0218\n",
      "Epoch 72/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0244 - val_loss: 0.0221\n",
      "Epoch 73/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0224\n",
      "Epoch 74/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0238 - val_loss: 0.0219\n",
      "Epoch 75/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0216\n",
      "Epoch 76/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0232 - val_loss: 0.0216\n",
      "Epoch 77/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0246 - val_loss: 0.0217\n",
      "Epoch 78/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0248 - val_loss: 0.0228\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0223\n",
      "Epoch 80/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0237 - val_loss: 0.0216\n",
      "Epoch 81/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0240 - val_loss: 0.0214\n",
      "Epoch 82/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0217\n",
      "Epoch 83/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0216\n",
      "Epoch 84/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0214\n",
      "Epoch 85/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0213\n",
      "Epoch 86/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0234 - val_loss: 0.0221\n",
      "Epoch 87/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0237 - val_loss: 0.0213\n",
      "Epoch 88/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0211\n",
      "Epoch 89/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0240 - val_loss: 0.0219\n",
      "Epoch 90/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0218\n",
      "Epoch 91/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0211\n",
      "Epoch 92/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0231 - val_loss: 0.0211\n",
      "Epoch 93/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0210\n",
      "Epoch 94/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0234 - val_loss: 0.0210\n",
      "Epoch 95/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0216\n",
      "Epoch 96/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0233 - val_loss: 0.0215\n",
      "Epoch 97/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0235 - val_loss: 0.0209\n",
      "Epoch 98/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0209\n",
      "Epoch 99/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0209\n",
      "Epoch 100/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 101/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 102/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0209\n",
      "Epoch 103/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0210\n",
      "Epoch 104/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0240 - val_loss: 0.0210\n",
      "Epoch 105/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0215\n",
      "Epoch 106/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0209\n",
      "Epoch 107/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0234 - val_loss: 0.0207\n",
      "Epoch 108/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0212\n",
      "Epoch 109/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0212\n",
      "Epoch 110/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0208\n",
      "Epoch 111/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0206\n",
      "Epoch 112/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0209\n",
      "Epoch 113/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0209\n",
      "Epoch 114/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0206\n",
      "Epoch 115/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0238 - val_loss: 0.0208\n",
      "Epoch 116/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0230 - val_loss: 0.0212\n",
      "Epoch 117/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 118/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0232 - val_loss: 0.0208\n",
      "Epoch 119/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 120/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0205\n",
      "Epoch 121/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0235 - val_loss: 0.0205\n",
      "Epoch 122/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0211\n",
      "Epoch 123/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0240 - val_loss: 0.0208\n",
      "Epoch 124/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0207\n",
      "Epoch 125/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0236 - val_loss: 0.0206\n",
      "Epoch 126/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0208\n",
      "Epoch 127/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0205\n",
      "Epoch 128/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0211\n",
      "Epoch 129/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0210\n",
      "Epoch 130/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 131/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0248 - val_loss: 0.0204\n",
      "Epoch 132/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0238 - val_loss: 0.0211\n",
      "Epoch 133/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0206\n",
      "Epoch 134/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 135/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 136/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0205\n",
      "Epoch 137/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 138/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0205\n",
      "Epoch 139/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0205\n",
      "Epoch 140/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 141/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 142/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 143/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0238 - val_loss: 0.0203\n",
      "Epoch 144/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0246 - val_loss: 0.0206\n",
      "Epoch 145/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0213\n",
      "Epoch 146/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 147/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0203\n",
      "Epoch 148/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0247 - val_loss: 0.0208\n",
      "Epoch 149/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0217\n",
      "Epoch 150/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0244 - val_loss: 0.0207\n",
      "Epoch 151/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 152/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0235 - val_loss: 0.0205\n",
      "Epoch 153/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0247 - val_loss: 0.0204\n",
      "Epoch 154/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0239 - val_loss: 0.0212\n",
      "Epoch 155/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0215\n",
      "Epoch 156/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0242 - val_loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0241 - val_loss: 0.0206\n",
      "Epoch 158/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0243 - val_loss: 0.0212\n",
      "Epoch 159/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0213\n",
      "Epoch 160/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0236 - val_loss: 0.0206\n",
      "Epoch 161/1000\n",
      "150/150 [==============================] - 0s 160us/step - loss: 0.0234 - val_loss: 0.0206\n",
      "Epoch 162/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0243 - val_loss: 0.0207\n",
      "Epoch 163/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0248 - val_loss: 0.0215\n",
      "Epoch 164/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0248 - val_loss: 0.0218\n",
      "Epoch 165/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0243 - val_loss: 0.0212\n",
      "Epoch 166/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 167/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 168/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0241 - val_loss: 0.0209\n",
      "Epoch 169/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0207\n",
      "Epoch 170/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0237 - val_loss: 0.0208\n",
      "Epoch 171/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0208\n",
      "Epoch 172/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0205\n",
      "Epoch 173/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 174/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 175/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 176/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0241 - val_loss: 0.0204\n",
      "Epoch 177/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0207\n",
      "Epoch 178/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 179/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 180/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 181/1000\n",
      "150/150 [==============================] - 0s 160us/step - loss: 0.0233 - val_loss: 0.0206\n",
      "Epoch 182/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 183/1000\n",
      "150/150 [==============================] - 0s 207us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 184/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 185/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 186/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 187/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 188/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 189/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 190/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 191/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 192/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0202\n",
      "Epoch 193/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 194/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0245 - val_loss: 0.0214\n",
      "Epoch 195/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0238 - val_loss: 0.0202\n",
      "Epoch 196/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 197/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0250 - val_loss: 0.0205\n",
      "Epoch 198/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0207\n",
      "Epoch 199/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0206\n",
      "Epoch 200/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 201/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0244 - val_loss: 0.0210\n",
      "Epoch 202/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0245 - val_loss: 0.0218\n",
      "Epoch 203/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0231 - val_loss: 0.0215\n",
      "Epoch 204/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0240 - val_loss: 0.0203\n",
      "Epoch 205/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 206/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 207/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 208/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 209/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 210/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 211/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 212/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0256 - val_loss: 0.0217\n",
      "Epoch 213/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0235 - val_loss: 0.0210\n",
      "Epoch 214/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0246 - val_loss: 0.0203\n",
      "Epoch 215/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 216/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0243 - val_loss: 0.0204\n",
      "Epoch 217/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 218/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 219/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0204\n",
      "Epoch 220/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 221/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 222/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0234 - val_loss: 0.0209\n",
      "Epoch 223/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0210\n",
      "Epoch 224/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0241 - val_loss: 0.0204\n",
      "Epoch 225/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0240 - val_loss: 0.0203\n",
      "Epoch 226/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0241 - val_loss: 0.0206\n",
      "Epoch 227/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0236 - val_loss: 0.0209\n",
      "Epoch 228/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0207\n",
      "Epoch 229/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 230/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0239 - val_loss: 0.0202\n",
      "Epoch 231/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0241 - val_loss: 0.0205\n",
      "Epoch 232/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0239 - val_loss: 0.0210\n",
      "Epoch 233/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0212\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 80us/step - loss: 0.0239 - val_loss: 0.0205\n",
      "Epoch 235/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 236/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 237/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0206\n",
      "Epoch 238/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 239/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 240/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0211\n",
      "Epoch 241/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 242/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 243/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 244/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0249 - val_loss: 0.0210\n",
      "Epoch 245/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0219\n",
      "Epoch 246/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0212\n",
      "Epoch 247/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0242 - val_loss: 0.0203\n",
      "Epoch 248/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0208\n",
      "Epoch 249/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0211\n",
      "Epoch 250/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 251/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0255 - val_loss: 0.0202\n",
      "Epoch 252/1000\n",
      "150/150 [==============================] - 0s 140us/step - loss: 0.0256 - val_loss: 0.0207\n",
      "Epoch 253/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0246 - val_loss: 0.0212\n",
      "Epoch 254/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 255/1000\n",
      "150/150 [==============================] - 0s 140us/step - loss: 0.0244 - val_loss: 0.0205\n",
      "Epoch 256/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.020 - 0s 107us/step - loss: 0.0235 - val_loss: 0.0207\n",
      "Epoch 257/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 258/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 259/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 260/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 261/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0237 - val_loss: 0.0203\n",
      "Epoch 262/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 263/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0203\n",
      "Epoch 264/1000\n",
      "150/150 [==============================] - 0s 140us/step - loss: 0.0236 - val_loss: 0.0205\n",
      "Epoch 265/1000\n",
      "150/150 [==============================] - 0s 153us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 266/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.020 - 0s 120us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 267/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 268/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0201\n",
      "Epoch 269/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 270/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0202\n",
      "Epoch 271/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0204\n",
      "Epoch 272/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 273/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 274/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0201\n",
      "Epoch 275/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 276/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0206\n",
      "Epoch 277/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 278/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 279/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0205\n",
      "Epoch 280/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 281/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 282/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.020 - 0s 113us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 283/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 284/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 285/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 286/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 287/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 288/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 289/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 290/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 291/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 292/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 293/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0241 - val_loss: 0.0204\n",
      "Epoch 294/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0227 - val_loss: 0.0208\n",
      "Epoch 295/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 296/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0236 - val_loss: 0.0201\n",
      "Epoch 297/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 298/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0204\n",
      "Epoch 299/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0229 - val_loss: 0.0209\n",
      "Epoch 300/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0204\n",
      "Epoch 301/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 302/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 303/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 304/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 305/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.017 - 0s 107us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 306/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 307/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 308/1000\n",
      "150/150 [==============================] - 0s 140us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 309/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 310/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0243 - val_loss: 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0275 - val_loss: 0.0212\n",
      "Epoch 312/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0240 - val_loss: 0.0238\n",
      "Epoch 313/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0219\n",
      "Epoch 314/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0272 - val_loss: 0.0209\n",
      "Epoch 315/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0257 - val_loss: 0.0209\n",
      "Epoch 316/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.022 - 0s 120us/step - loss: 0.0237 - val_loss: 0.0221\n",
      "Epoch 317/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0249 - val_loss: 0.0209\n",
      "Epoch 318/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0209\n",
      "Epoch 319/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0246 - val_loss: 0.0205\n",
      "Epoch 320/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0242 - val_loss: 0.0207\n",
      "Epoch 321/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 322/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0204\n",
      "Epoch 323/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0242 - val_loss: 0.0205\n",
      "Epoch 324/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0208\n",
      "Epoch 325/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 326/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0238 - val_loss: 0.0203\n",
      "Epoch 327/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0206\n",
      "Epoch 328/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 329/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0207\n",
      "Epoch 330/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 331/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0240 - val_loss: 0.0204\n",
      "Epoch 332/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0249 - val_loss: 0.0212\n",
      "Epoch 333/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0216\n",
      "Epoch 334/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0238 - val_loss: 0.0204\n",
      "Epoch 335/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 336/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0206\n",
      "Epoch 337/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0207\n",
      "Epoch 338/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 339/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 340/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0205\n",
      "Epoch 341/1000\n",
      "150/150 [==============================] - 0s 147us/step - loss: 0.0240 - val_loss: 0.0205\n",
      "Epoch 342/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0245 - val_loss: 0.0205\n",
      "Epoch 343/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0212\n",
      "Epoch 344/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0209\n",
      "Epoch 345/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0243 - val_loss: 0.0210\n",
      "Epoch 346/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 347/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0207\n",
      "Epoch 348/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0240 - val_loss: 0.0214\n",
      "Epoch 349/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0204\n",
      "Epoch 350/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 351/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 352/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0235 - val_loss: 0.0207\n",
      "Epoch 353/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 354/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 355/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 356/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 357/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 358/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 359/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 360/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0228 - val_loss: 0.0202\n",
      "Epoch 361/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 362/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 363/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 364/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 365/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 366/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 367/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 368/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 369/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.028 - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 370/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0239 - val_loss: 0.0203\n",
      "Epoch 371/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0255 - val_loss: 0.0210\n",
      "Epoch 372/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0228\n",
      "Epoch 373/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0226\n",
      "Epoch 374/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0244 - val_loss: 0.0207\n",
      "Epoch 375/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 376/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0208\n",
      "Epoch 377/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0208\n",
      "Epoch 378/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 379/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0235 - val_loss: 0.0206\n",
      "Epoch 380/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0227 - val_loss: 0.0205\n",
      "Epoch 381/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 382/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 383/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 384/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 385/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 386/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 387/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 107us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 389/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0228 - val_loss: 0.0202\n",
      "Epoch 390/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 391/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 392/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 393/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 394/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 395/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0208\n",
      "Epoch 396/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 397/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 398/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 399/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0204\n",
      "Epoch 400/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0204\n",
      "Epoch 401/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0249 - val_loss: 0.0213\n",
      "Epoch 402/1000\n",
      "150/150 [==============================] - 0s 147us/step - loss: 0.0230 - val_loss: 0.0213\n",
      "Epoch 403/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0244 - val_loss: 0.0205\n",
      "Epoch 404/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 405/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 406/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 407/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0206\n",
      "Epoch 408/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0239 - val_loss: 0.0210\n",
      "Epoch 409/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0213\n",
      "Epoch 410/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0239 - val_loss: 0.0203\n",
      "Epoch 411/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0238 - val_loss: 0.0201\n",
      "Epoch 412/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 413/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 414/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0202\n",
      "Epoch 415/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0212\n",
      "Epoch 416/1000\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0239 - val_loss: 0.0201\n",
      "Epoch 417/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0202\n",
      "Epoch 418/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0211\n",
      "Epoch 419/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 420/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 421/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 422/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 423/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0213\n",
      "Epoch 424/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 425/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 426/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 427/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 428/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0201\n",
      "Epoch 429/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 430/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0238 - val_loss: 0.0204\n",
      "Epoch 431/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0244 - val_loss: 0.0204\n",
      "Epoch 432/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 433/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 434/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 435/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 436/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 437/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 438/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 439/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 440/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0201\n",
      "Epoch 441/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0234 - val_loss: 0.0205\n",
      "Epoch 442/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.030 - 0s 87us/step - loss: 0.0242 - val_loss: 0.0203\n",
      "Epoch 443/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0245 - val_loss: 0.0210\n",
      "Epoch 444/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0228 - val_loss: 0.0224\n",
      "Epoch 445/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0257 - val_loss: 0.0202\n",
      "Epoch 446/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.021 - 0s 80us/step - loss: 0.0241 - val_loss: 0.0211\n",
      "Epoch 447/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/step - loss: 0.0240 - val_loss: 0.0213\n",
      "Epoch 448/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0212\n",
      "Epoch 449/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/step - loss: 0.0243 - val_loss: 0.0206\n",
      "Epoch 450/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 451/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 452/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0209\n",
      "Epoch 453/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0243 - val_loss: 0.0202\n",
      "Epoch 454/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0252 - val_loss: 0.0203\n",
      "Epoch 455/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.024 - 0s 107us/step - loss: 0.0225 - val_loss: 0.0211\n",
      "Epoch 456/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 457/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 458/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0236 - val_loss: 0.0201\n",
      "Epoch 459/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0227 - val_loss: 0.0203\n",
      "Epoch 460/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 461/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 462/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 463/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 464/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 465/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0240 - val_loss: 0.0201\n",
      "Epoch 466/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 467/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0227 - val_loss: 0.0202\n",
      "Epoch 468/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0238 - val_loss: 0.0202\n",
      "Epoch 469/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 470/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 471/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 472/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 473/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0241 - val_loss: 0.0208\n",
      "Epoch 474/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.023 - 0s 87us/step - loss: 0.0242 - val_loss: 0.0207\n",
      "Epoch 475/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0206\n",
      "Epoch 476/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0234 - val_loss: 0.0205\n",
      "Epoch 477/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0242 - val_loss: 0.0203\n",
      "Epoch 478/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0206\n",
      "Epoch 479/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0205\n",
      "Epoch 480/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0206\n",
      "Epoch 481/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 482/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0240 - val_loss: 0.0206\n",
      "Epoch 483/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0201\n",
      "Epoch 484/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 485/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 486/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0231 - val_loss: 0.0208\n",
      "Epoch 487/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 488/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 489/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 490/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0242 - val_loss: 0.0206\n",
      "Epoch 491/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0244 - val_loss: 0.0206\n",
      "Epoch 492/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0244 - val_loss: 0.0209\n",
      "Epoch 493/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0243 - val_loss: 0.0208\n",
      "Epoch 494/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0227 - val_loss: 0.0208\n",
      "Epoch 495/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0239 - val_loss: 0.0202\n",
      "Epoch 496/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0253 - val_loss: 0.0204\n",
      "Epoch 497/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0255 - val_loss: 0.0217\n",
      "Epoch 498/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 499/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0257 - val_loss: 0.0203\n",
      "Epoch 500/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0276 - val_loss: 0.0219\n",
      "Epoch 501/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0256 - val_loss: 0.0236\n",
      "Epoch 502/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0229\n",
      "Epoch 503/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0256 - val_loss: 0.0210\n",
      "Epoch 504/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0254 - val_loss: 0.0208\n",
      "Epoch 505/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0237 - val_loss: 0.0211\n",
      "Epoch 506/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0210\n",
      "Epoch 507/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0241 - val_loss: 0.0203\n",
      "Epoch 508/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 509/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 510/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0234 - val_loss: 0.0205\n",
      "Epoch 511/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0242 - val_loss: 0.0204\n",
      "Epoch 512/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0207\n",
      "Epoch 513/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 514/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 515/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 516/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.023 - 0s 100us/step - loss: 0.0229 - val_loss: 0.0207\n",
      "Epoch 517/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 518/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0245 - val_loss: 0.0207\n",
      "Epoch 519/1000\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0235 - val_loss: 0.0212\n",
      "Epoch 520/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0211\n",
      "Epoch 521/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0242 - val_loss: 0.0204\n",
      "Epoch 522/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0241 - val_loss: 0.0202\n",
      "Epoch 523/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 524/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 525/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0245 - val_loss: 0.0201\n",
      "Epoch 526/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 527/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0244 - val_loss: 0.0207\n",
      "Epoch 528/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 529/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 530/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0237 - val_loss: 0.0206\n",
      "Epoch 531/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0235 - val_loss: 0.0209\n",
      "Epoch 532/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0201\n",
      "Epoch 533/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 534/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 535/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 536/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0242 - val_loss: 0.0208\n",
      "Epoch 537/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0235 - val_loss: 0.0221\n",
      "Epoch 538/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0240 - val_loss: 0.0205\n",
      "Epoch 539/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0239 - val_loss: 0.0213\n",
      "Epoch 540/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0241 - val_loss: 0.0208\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0206\n",
      "Epoch 542/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0227 - val_loss: 0.0208\n",
      "Epoch 543/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 544/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 545/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0256 - val_loss: 0.0203\n",
      "Epoch 546/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0216\n",
      "Epoch 547/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0205\n",
      "Epoch 548/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 549/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 550/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.027 - 0s 107us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 551/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 552/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 553/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0210\n",
      "Epoch 554/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 555/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 556/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 557/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0238 - val_loss: 0.0205\n",
      "Epoch 558/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 559/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 560/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 561/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0205\n",
      "Epoch 562/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0236 - val_loss: 0.0212\n",
      "Epoch 563/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0205\n",
      "Epoch 564/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0237 - val_loss: 0.0203\n",
      "Epoch 565/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0232 - val_loss: 0.0208\n",
      "Epoch 566/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 567/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 568/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0236 - val_loss: 0.0202\n",
      "Epoch 569/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0235 - val_loss: 0.0214\n",
      "Epoch 570/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0202\n",
      "Epoch 571/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 572/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 573/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 574/1000\n",
      "150/150 [==============================] - 0s 140us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 575/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0228 - val_loss: 0.0208\n",
      "Epoch 576/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0202\n",
      "Epoch 577/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0243 - val_loss: 0.0212\n",
      "Epoch 578/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0239 - val_loss: 0.0211\n",
      "Epoch 579/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0236 - val_loss: 0.0210\n",
      "Epoch 580/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0239 - val_loss: 0.0213\n",
      "Epoch 581/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0247 - val_loss: 0.0204\n",
      "Epoch 582/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0212\n",
      "Epoch 583/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0245 - val_loss: 0.0209\n",
      "Epoch 584/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 585/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0241 - val_loss: 0.0204\n",
      "Epoch 586/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0220\n",
      "Epoch 587/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0209\n",
      "Epoch 588/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0242 - val_loss: 0.0201\n",
      "Epoch 589/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0209\n",
      "Epoch 590/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0244 - val_loss: 0.0210\n",
      "Epoch 591/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0238 - val_loss: 0.0217\n",
      "Epoch 592/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 593/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0241 - val_loss: 0.0202\n",
      "Epoch 594/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 595/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0205\n",
      "Epoch 596/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 597/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 598/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0205\n",
      "Epoch 599/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 600/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 601/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 602/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 603/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 604/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0205\n",
      "Epoch 605/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0239 - val_loss: 0.0206\n",
      "Epoch 606/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 607/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 608/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 609/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 610/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 611/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 612/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 613/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 614/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 615/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 616/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 617/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 618/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 619/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 620/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 621/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 622/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 623/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 624/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0208\n",
      "Epoch 625/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0203\n",
      "Epoch 626/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 627/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 628/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0229 - val_loss: 0.0201\n",
      "Epoch 629/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0201\n",
      "Epoch 630/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 631/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 632/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 633/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0201\n",
      "Epoch 634/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 635/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 636/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 637/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 638/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0238 - val_loss: 0.0201\n",
      "Epoch 639/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0209\n",
      "Epoch 640/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0207\n",
      "Epoch 641/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0249 - val_loss: 0.0207\n",
      "Epoch 642/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0241 - val_loss: 0.0215\n",
      "Epoch 643/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 644/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0234 - val_loss: 0.0205\n",
      "Epoch 645/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 646/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.027 - 0s 80us/step - loss: 0.0241 - val_loss: 0.0206\n",
      "Epoch 647/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 648/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 649/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 650/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 651/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 652/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 653/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 654/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0239 - val_loss: 0.0210\n",
      "Epoch 655/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 656/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0240 - val_loss: 0.0202\n",
      "Epoch 657/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0211\n",
      "Epoch 658/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 659/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0202\n",
      "Epoch 660/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 661/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0240 - val_loss: 0.0207\n",
      "Epoch 662/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0244 - val_loss: 0.0210\n",
      "Epoch 663/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0212\n",
      "Epoch 664/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0248 - val_loss: 0.0206\n",
      "Epoch 665/1000\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 666/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 667/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 668/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0201\n",
      "Epoch 669/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 670/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 671/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 672/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 673/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 674/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0241 - val_loss: 0.0205\n",
      "Epoch 675/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0243 - val_loss: 0.0212\n",
      "Epoch 676/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0243 - val_loss: 0.0221\n",
      "Epoch 677/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0214\n",
      "Epoch 678/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0241 - val_loss: 0.0206\n",
      "Epoch 679/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 680/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 681/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0238 - val_loss: 0.0203\n",
      "Epoch 682/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0241 - val_loss: 0.0204\n",
      "Epoch 683/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0253 - val_loss: 0.0206\n",
      "Epoch 684/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0258 - val_loss: 0.0226\n",
      "Epoch 685/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0226 - val_loss: 0.0219\n",
      "Epoch 686/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 687/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 688/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 689/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0236 - val_loss: 0.0202\n",
      "Epoch 690/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0246 - val_loss: 0.0207\n",
      "Epoch 691/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0214\n",
      "Epoch 692/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0205\n",
      "Epoch 693/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 694/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 695/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 87us/step - loss: 0.0234 - val_loss: 0.0207\n",
      "Epoch 696/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 697/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 698/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 699/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 700/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/step - loss: 0.0245 - val_loss: 0.0206\n",
      "Epoch 701/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0216\n",
      "Epoch 702/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0249 - val_loss: 0.0202\n",
      "Epoch 703/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0207\n",
      "Epoch 704/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0248 - val_loss: 0.0210\n",
      "Epoch 705/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0211\n",
      "Epoch 706/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0241 - val_loss: 0.0203\n",
      "Epoch 707/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 708/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 709/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 710/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 711/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0209\n",
      "Epoch 712/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0241 - val_loss: 0.0206\n",
      "Epoch 713/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 714/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0201\n",
      "Epoch 715/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0228 - val_loss: 0.0208\n",
      "Epoch 716/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0201\n",
      "Epoch 717/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 718/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 719/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 720/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 721/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0201\n",
      "Epoch 722/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0203\n",
      "Epoch 723/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0246 - val_loss: 0.0207\n",
      "Epoch 724/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0222 - val_loss: 0.0213\n",
      "Epoch 725/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0245 - val_loss: 0.0201\n",
      "Epoch 726/1000\n",
      "150/150 [==============================] - 0s 153us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 727/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 728/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 729/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 730/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0206\n",
      "Epoch 731/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0204\n",
      "Epoch 732/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 733/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0206\n",
      "Epoch 734/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 735/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 736/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 737/1000\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 738/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0241 - val_loss: 0.0205\n",
      "Epoch 739/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0232 - val_loss: 0.0213\n",
      "Epoch 740/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 741/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0209\n",
      "Epoch 742/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0245 - val_loss: 0.0211\n",
      "Epoch 743/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0206\n",
      "Epoch 744/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 745/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 746/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 747/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0212\n",
      "Epoch 748/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0205\n",
      "Epoch 749/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 750/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 751/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 752/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0239 - val_loss: 0.0207\n",
      "Epoch 753/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0205\n",
      "Epoch 754/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0205\n",
      "Epoch 755/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0238 - val_loss: 0.0209\n",
      "Epoch 756/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 757/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0246 - val_loss: 0.0202\n",
      "Epoch 758/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0234 - val_loss: 0.0210\n",
      "Epoch 759/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 760/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0239 - val_loss: 0.0203\n",
      "Epoch 761/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 762/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 763/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 764/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0208\n",
      "Epoch 765/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0207\n",
      "Epoch 766/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0239 - val_loss: 0.0207\n",
      "Epoch 767/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 768/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 769/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0206\n",
      "Epoch 770/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0238 - val_loss: 0.0201\n",
      "Epoch 771/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0242 - val_loss: 0.0205\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 100us/step - loss: 0.0250 - val_loss: 0.0205\n",
      "Epoch 773/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0237 - val_loss: 0.0209\n",
      "Epoch 774/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0208\n",
      "Epoch 775/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 776/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 777/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0247 - val_loss: 0.0206\n",
      "Epoch 778/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 779/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0202\n",
      "Epoch 780/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 781/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0207\n",
      "Epoch 782/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 783/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 784/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0206\n",
      "Epoch 785/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0201\n",
      "Epoch 786/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 787/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 788/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 789/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 790/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0201\n",
      "Epoch 791/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 792/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 793/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 794/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 795/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0241 - val_loss: 0.0202\n",
      "Epoch 796/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0237 - val_loss: 0.0214\n",
      "Epoch 797/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0258 - val_loss: 0.0209\n",
      "Epoch 798/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0248 - val_loss: 0.0214\n",
      "Epoch 799/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 800/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0208\n",
      "Epoch 801/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 802/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 803/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 804/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0208\n",
      "Epoch 805/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 806/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 807/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.027 - 0s 100us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 808/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 809/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 810/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0206\n",
      "Epoch 811/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 812/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0243 - val_loss: 0.0202\n",
      "Epoch 813/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0230 - val_loss: 0.0208\n",
      "Epoch 814/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 815/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 816/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 817/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 818/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 819/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 820/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0245 - val_loss: 0.0204\n",
      "Epoch 821/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0210\n",
      "Epoch 822/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 823/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0204\n",
      "Epoch 824/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0237 - val_loss: 0.0201\n",
      "Epoch 825/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0201\n",
      "Epoch 826/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 827/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0201\n",
      "Epoch 828/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 829/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 830/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0255 - val_loss: 0.0204\n",
      "Epoch 831/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0276 - val_loss: 0.0218\n",
      "Epoch 832/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0242 - val_loss: 0.0231\n",
      "Epoch 833/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0240 - val_loss: 0.0220\n",
      "Epoch 834/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0240 - val_loss: 0.0205\n",
      "Epoch 835/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 836/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0210\n",
      "Epoch 837/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0238 - val_loss: 0.0204\n",
      "Epoch 838/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0235 - val_loss: 0.0206\n",
      "Epoch 839/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 840/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 841/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 842/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 843/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 844/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 845/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 846/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 847/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 848/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 850/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 851/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 852/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 853/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 854/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 855/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0201\n",
      "Epoch 856/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0209\n",
      "Epoch 857/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 858/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 859/1000\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 860/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0239 - val_loss: 0.0200\n",
      "Epoch 861/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0228 - val_loss: 0.0202\n",
      "Epoch 862/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 863/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 864/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 865/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 866/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 867/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 868/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 869/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 870/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0202\n",
      "Epoch 871/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0206\n",
      "Epoch 872/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0235 - val_loss: 0.0215\n",
      "Epoch 873/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0206\n",
      "Epoch 874/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0242 - val_loss: 0.0203\n",
      "Epoch 875/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0239 - val_loss: 0.0205\n",
      "Epoch 876/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0209\n",
      "Epoch 877/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0238 - val_loss: 0.0207\n",
      "Epoch 878/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0245 - val_loss: 0.0207\n",
      "Epoch 879/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 880/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0236 - val_loss: 0.0205\n",
      "Epoch 881/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0229 - val_loss: 0.0203\n",
      "Epoch 882/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 883/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 884/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0208\n",
      "Epoch 885/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0209\n",
      "Epoch 886/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 887/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0241 - val_loss: 0.0201\n",
      "Epoch 888/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0235 - val_loss: 0.0206\n",
      "Epoch 889/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0242 - val_loss: 0.0215\n",
      "Epoch 890/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0241 - val_loss: 0.0210\n",
      "Epoch 891/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0241 - val_loss: 0.0207\n",
      "Epoch 892/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0210\n",
      "Epoch 893/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0208\n",
      "Epoch 894/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 895/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 896/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0250 - val_loss: 0.0205\n",
      "Epoch 897/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0210\n",
      "Epoch 898/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 899/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0245 - val_loss: 0.0220\n",
      "Epoch 900/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0236 - val_loss: 0.0209\n",
      "Epoch 901/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0243 - val_loss: 0.0213\n",
      "Epoch 902/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0240 - val_loss: 0.0212\n",
      "Epoch 903/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0249 - val_loss: 0.0203\n",
      "Epoch 904/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0239 - val_loss: 0.0217\n",
      "Epoch 905/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0221\n",
      "Epoch 906/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0244 - val_loss: 0.0204\n",
      "Epoch 907/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0228 - val_loss: 0.0203\n",
      "Epoch 908/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 909/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 910/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0234 - val_loss: 0.0204\n",
      "Epoch 911/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 912/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0229 - val_loss: 0.0201\n",
      "Epoch 913/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0238 - val_loss: 0.0205\n",
      "Epoch 914/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 915/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0202\n",
      "Epoch 916/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 917/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0206\n",
      "Epoch 918/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0243 - val_loss: 0.0204\n",
      "Epoch 919/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 920/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 921/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 922/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0241 - val_loss: 0.0203\n",
      "Epoch 923/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0227 - val_loss: 0.0213\n",
      "Epoch 924/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 925/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 926/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 927/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 928/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 929/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 930/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 931/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0241 - val_loss: 0.0204\n",
      "Epoch 932/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 933/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 934/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 935/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0241 - val_loss: 0.0204\n",
      "Epoch 936/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0230 - val_loss: 0.0208\n",
      "Epoch 937/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0231 - val_loss: 0.0207\n",
      "Epoch 938/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 939/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0228 - val_loss: 0.0211\n",
      "Epoch 940/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 941/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0240 - val_loss: 0.0202\n",
      "Epoch 942/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 943/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 944/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 945/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 946/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 947/1000\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 948/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 949/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0231 - val_loss: 0.0203\n",
      "Epoch 950/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0201\n",
      "Epoch 951/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0238 - val_loss: 0.0202\n",
      "Epoch 952/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 953/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 954/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 955/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 956/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 957/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0201\n",
      "Epoch 958/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0237 - val_loss: 0.0201\n",
      "Epoch 959/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 960/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0204\n",
      "Epoch 961/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 962/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0202\n",
      "Epoch 963/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 964/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0230 - val_loss: 0.0203\n",
      "Epoch 965/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0237 - val_loss: 0.0203\n",
      "Epoch 966/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 967/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0252 - val_loss: 0.0202\n",
      "Epoch 968/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0243 - val_loss: 0.0221\n",
      "Epoch 969/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0256 - val_loss: 0.0225\n",
      "Epoch 970/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0247 - val_loss: 0.0221\n",
      "Epoch 971/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0239 - val_loss: 0.0215\n",
      "Epoch 972/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0206\n",
      "Epoch 973/1000\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.0244 - val_loss: 0.0203\n",
      "Epoch 974/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0256 - val_loss: 0.0209\n",
      "Epoch 975/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0234 - val_loss: 0.0218\n",
      "Epoch 976/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0238 - val_loss: 0.0210\n",
      "Epoch 977/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 978/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0233 - val_loss: 0.0203\n",
      "Epoch 979/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 980/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 981/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 982/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 983/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 984/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 985/1000\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0232 - val_loss: 0.0208\n",
      "Epoch 986/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 987/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 988/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 989/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 990/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 991/1000\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0236 - val_loss: 0.0203\n",
      "Epoch 992/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0236 - val_loss: 0.0210\n",
      "Epoch 993/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0203\n",
      "Epoch 994/1000\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0202\n",
      "Epoch 995/1000\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.0228 - val_loss: 0.0210\n",
      "Epoch 996/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 997/1000\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0232 - val_loss: 0.0202\n",
      "Epoch 998/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 999/1000\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 1000/1000\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0233 - val_loss: 0.0209\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, Y_train, epochs=1000, verbose=1, validation_data=(X_test, Y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Plot the training and validation error curves. Did the training converge? If not then go back and increase the number of training epochs. Also try different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'], label='training')\n",
    "plt.plot(h.history['val_loss'], label='validation')\n",
    "plt.yscale('log')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Plot the data points and the neural network output to see if the model was able to well approoximate the underlying function. If it is not the case then go back to **b)** and try to solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, color='red', s=5)\n",
    "plt.plot(sorted(X), model.predict(sorted(X)), color='b', linewidth=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (Binary classification)\n",
    "\n",
    "Now will solve a binary classification task. The training data consists of data points $(x_i,y_i)$ with $x_i \\in \\mathcal{R}^2$ and $y_i \\in \\lbrace 0, 1\\rbrace$. \n",
    "\n",
    "**a)** Generate the data using the methods `make_moons` or `make_circles` from the package `sklearn.datasets`. Plot the data points (blue for class 0 and red for class 1). Also split the data set into training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Your code goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Create a neural network using `binary_crossentropy` as loss function and `accuracy` as a metric to evaluate the results and train it using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Your code goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Plot the training and validation error curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Your code goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Plot the data points and color the surface according to the probability of belonging to each class. This should make visible the decision area and its uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Your code goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
